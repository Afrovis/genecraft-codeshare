# Sharing Simple Rust Neural Networks

As a token of gratitude to what I learned from others, I'm open sourcing both my Rust fixed neural network and a simple Rust NEAT implementation. Most likely, both can be improved and optimized. As of July 2024, the NEAT algorithm has a bug and sometimes creates nodes on the same layer. Haven't focussed on fixing that yet.

If you use this in any public or derived work, please attribute Genecraft. Also– If you build something cool, I'd love to see and share it. Feel free to send a video and I'll add it as an examples below.

Email genecraftsimulator@gmail.com or message me on reddit.com/u/genecraft for any questions or suggestions.

# Collaboration (Science, Code, Genecraft, etc)

I am not a coder– Rather an amateur neuroscientist that leverages LLMs to help bring my ideas to life. If you'd like to collaborate scientifically or in another way, please reach out to genecraftsimulator@gmail.com or message me on reddit.com/u/genecraft


# About NEAT (NeuroEvolution of Augemented Topologies)

This NEAT is a simple adaptation from this paper:
Stanley, K. O., & Miikkulainen, R. (2002). Evolving neural networks through augmenting topologies. Evolutionary computation, 10(2), 99-127.
https://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf


# Performance in Simulations


NEAT performs much better and leads to more interesting behavior compared to simple fixed neural networks, especially the more complex the simulation becomes.

Comparison in action below:
https://www.youtube.com/watch?v=-fowSwAVUWg

